# generated by datamodel-codegen:
#   filename:  vllm-bootstrap-openapi.json
#   timestamp: 2026-02-17T19:59:17+00:00

from __future__ import annotations

from enum import StrEnum
from typing import Any

from pydantic import AwareDatetime, BaseModel, Field, constr


class GPUStatsResponse(BaseModel):
    gpu_id: int = Field(..., title="Gpu Id")
    uuid: str | None = Field(None, title="Uuid")
    name: str = Field(..., title="Name")
    utilization_percent: float | None = Field(None, title="Utilization Percent")
    memory_total_mib: int | None = Field(None, title="Memory Total Mib")
    memory_used_mib: int | None = Field(None, title="Memory Used Mib")
    memory_free_mib: int | None = Field(None, title="Memory Free Mib")
    temperature_c: int | None = Field(None, title="Temperature C")
    power_draw_watts: float | None = Field(None, title="Power Draw Watts")
    power_limit_watts: float | None = Field(None, title="Power Limit Watts")


class LaunchRequest(BaseModel):
    model: constr(min_length=1) = Field(
        ..., description="Model id/path passed to vLLM. Required.", title="Model"
    )
    gpu_ids: list[int] | None = Field(
        None,
        description="Specific GPU ids to allocate. Defaults to all visible GPUs.",
        title="Gpu Ids",
    )
    task: constr(pattern=r"^(embed|generate)$") | None = Field(
        "generate",
        description="Task type: 'generate' for text generation or 'embed' for embeddings.",
        title="Task",
    )
    extra_kwargs: dict[str, Any] | None = Field(
        None,
        description="Additional keyword arguments passed to vllm.LLM constructor.",
        title="Extra Kwargs",
    )


class LaunchState(StrEnum):
    bootstrapping = "bootstrapping"
    ready = "ready"
    stopping = "stopping"
    stopped = "stopped"
    failed = "failed"


class LogsResponse(BaseModel):
    launch_id: str = Field(..., title="Launch Id")
    offset: int = Field(..., title="Offset")
    next_offset: int = Field(..., title="Next Offset")
    content: str = Field(..., title="Content")


class SystemStatsResponse(BaseModel):
    collected_at: AwareDatetime = Field(..., title="Collected At")
    load_avg_1m: float | None = Field(None, title="Load Avg 1M")
    load_avg_5m: float | None = Field(None, title="Load Avg 5M")
    load_avg_15m: float | None = Field(None, title="Load Avg 15M")
    cpu_count: int | None = Field(None, title="Cpu Count")
    memory_total_bytes: int | None = Field(None, title="Memory Total Bytes")
    memory_available_bytes: int | None = Field(None, title="Memory Available Bytes")
    memory_used_bytes: int | None = Field(None, title="Memory Used Bytes")
    memory_utilization_percent: float | None = Field(
        None, title="Memory Utilization Percent"
    )
    host_memory_error: str | None = Field(None, title="Host Memory Error")
    gpu_count: int = Field(..., title="Gpu Count")
    gpus: list[GPUStatsResponse] = Field(..., title="Gpus")
    nvidia_smi_error: str | None = Field(None, title="Nvidia Smi Error")


class ValidationError(BaseModel):
    loc: list[str | int] = Field(..., title="Location")
    msg: str = Field(..., title="Message")
    type: str = Field(..., title="Error Type")
    input: Any | None = Field(None, title="Input")
    ctx: dict[str, Any] | None = Field(None, title="Context")


class HTTPValidationError(BaseModel):
    detail: list[ValidationError] | None = Field(None, title="Detail")


class LaunchResponse(BaseModel):
    launch_id: str = Field(..., title="Launch Id")
    model: str = Field(..., title="Model")
    gpu_ids: list[int] = Field(..., title="Gpu Ids")
    task: str = Field(..., title="Task")
    state: LaunchState
    created_at: AwareDatetime = Field(..., title="Created At")
    updated_at: AwareDatetime = Field(..., title="Updated At")
    error: str | None = Field(None, title="Error")
