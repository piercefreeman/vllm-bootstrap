# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: inference.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""

from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder

_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC, 6, 31, 1, "", "inference.proto"
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
    b'\n\x0finference.proto\x12\x0evllm_bootstrap"0\n\x0c\x45mbedRequest\x12\x11\n\tlaunch_id\x18\x01 \x01(\t\x12\r\n\x05texts\x18\x02 \x03(\t">\n\rEmbedResponse\x12-\n\nembeddings\x18\x01 \x03(\x0b\x32\x19.vllm_bootstrap.Embedding"\x1b\n\tEmbedding\x12\x0e\n\x06values\x18\x01 \x03(\x02"\x90\x01\n\x0f\x43ompleteRequest\x12\x11\n\tlaunch_id\x18\x01 \x01(\t\x12\x0e\n\x06prompt\x18\x02 \x01(\t\x12\x12\n\nmax_tokens\x18\x03 \x01(\x05\x12\x18\n\x0btemperature\x18\x04 \x01(\x02H\x00\x88\x01\x01\x12\x12\n\x05top_p\x18\x05 \x01(\x02H\x01\x88\x01\x01\x42\x0e\n\x0c_temperatureB\x08\n\x06_top_p"R\n\x10\x43ompleteResponse\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x15\n\rprompt_tokens\x18\x02 \x01(\x05\x12\x19\n\x11\x63ompletion_tokens\x18\x03 \x01(\x05\x32\xa7\x01\n\x10InferenceService\x12\x44\n\x05\x45mbed\x12\x1c.vllm_bootstrap.EmbedRequest\x1a\x1d.vllm_bootstrap.EmbedResponse\x12M\n\x08\x43omplete\x12\x1f.vllm_bootstrap.CompleteRequest\x1a .vllm_bootstrap.CompleteResponseb\x06proto3'
)

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, "inference_pb2", _globals)
if not _descriptor._USE_C_DESCRIPTORS:
    DESCRIPTOR._loaded_options = None
    _globals["_EMBEDREQUEST"]._serialized_start = 35
    _globals["_EMBEDREQUEST"]._serialized_end = 83
    _globals["_EMBEDRESPONSE"]._serialized_start = 85
    _globals["_EMBEDRESPONSE"]._serialized_end = 147
    _globals["_EMBEDDING"]._serialized_start = 149
    _globals["_EMBEDDING"]._serialized_end = 176
    _globals["_COMPLETEREQUEST"]._serialized_start = 179
    _globals["_COMPLETEREQUEST"]._serialized_end = 323
    _globals["_COMPLETERESPONSE"]._serialized_start = 325
    _globals["_COMPLETERESPONSE"]._serialized_end = 407
    _globals["_INFERENCESERVICE"]._serialized_start = 410
    _globals["_INFERENCESERVICE"]._serialized_end = 577
# @@protoc_insertion_point(module_scope)
